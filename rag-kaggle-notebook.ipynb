{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7912485,"sourceType":"datasetVersion","datasetId":4648615},{"sourceId":7946869,"sourceType":"datasetVersion","datasetId":4672898},{"sourceId":7949336,"sourceType":"datasetVersion","datasetId":4674712}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# install dependencies\n%pip install llampip install llama-indexa-index --quiet\n%pip install chromadb --quiet\n%pip install -U sentence-transformers --quiet\n%pip install llama-index-vector-stores-chroma --quiet\n%pip install llama-index-embeddings-huggingface --quiet\n%pip install llama-index-embeddings-instructor --quiet\n%pip install transformers accelerate\n%pip install llama-index-readers-web\n%pip install -i https://pypi.org/simple/ bitsandbytes --quiet\n%pip install llama-index-llms-huggingface --quiet\n%pip install llama-index-retrievers-bm25 --quiet","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom llama_index.core import SimpleDirectoryReader, VectorStoreIndex\nimport chromadb\nfrom sentence_transformers import SentenceTransformer\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core import StorageContext, Settings\nimport torch\nfrom llama_index.llms.huggingface import HuggingFaceLLM\nfrom llama_index.core import PromptTemplate\nfrom transformers import BitsAndBytesConfig\nfrom llama_index.core.prompts import PromptTemplate\nfrom llama_index.llms.huggingface import HuggingFaceLLM\nfrom llama_index.retrievers.bm25 import BM25Retriever\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nimport logging\nimport sys\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:54:34.066217Z","iopub.execute_input":"2024-03-26T16:54:34.066585Z","iopub.status.idle":"2024-03-26T16:54:44.357750Z","shell.execute_reply.started":"2024-03-26T16:54:34.066554Z","shell.execute_reply":"2024-03-26T16:54:44.356968Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# create documents directory if not existing\nif not os.path.exists(os.getcwd() + '/documents'):\n    os.makedirs('documents')\n\n# creating document folder if not existing\nfile_path = os.getcwd() + '/documents'\nfile_path = r'/kaggle/input/datetime-parser-dataset'\ntry:\n  documents = SimpleDirectoryReader(file_path).load_data()\n  parser = SentenceSplitter()\n  nodes = parser.get_nodes_from_documents(documents)\nexcept Exception as error:\n  print(f'{error}')","metadata":{"execution":{"iopub.status.busy":"2024-03-26T17:23:29.129342Z","iopub.execute_input":"2024-03-26T17:23:29.129744Z","iopub.status.idle":"2024-03-26T17:23:29.188640Z","shell.execute_reply.started":"2024-03-26T17:23:29.129710Z","shell.execute_reply":"2024-03-26T17:23:29.187886Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"embed_model = HuggingFaceEmbedding(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:54:46.080319Z","iopub.execute_input":"2024-03-26T16:54:46.080613Z","iopub.status.idle":"2024-03-26T16:54:49.785816Z","shell.execute_reply.started":"2024-03-26T16:54:46.080588Z","shell.execute_reply":"2024-03-26T16:54:49.784972Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"chroma_client = chromadb.EphemeralClient()\ntry:\n  chroma_client.delete_collection('embedding_docs')\nexcept Exception:\n  pass\nchroma_collection = chroma_client.create_collection(\"embedding_docs\")\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\nindex = VectorStoreIndex.from_documents(\n    documents, storage_context=storage_context, embed_model=embed_model, embed_batch_size=100\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T17:24:50.724717Z","iopub.execute_input":"2024-03-26T17:24:50.725798Z","iopub.status.idle":"2024-03-26T17:24:51.202657Z","shell.execute_reply.started":"2024-03-26T17:24:50.725764Z","shell.execute_reply":"2024-03-26T17:24:51.201853Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"secret_label = \"HF_TOKEN\"\nhf_token = UserSecretsClient().get_secret(secret_label)\n\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:54:53.811313Z","iopub.execute_input":"2024-03-26T16:54:53.811619Z","iopub.status.idle":"2024-03-26T16:54:54.001978Z","shell.execute_reply.started":"2024-03-26T16:54:53.811575Z","shell.execute_reply":"2024-03-26T16:54:54.001116Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"selected_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nSYSTEM_PROMPT = f\"\"\"You are a helptul AI assistant, you are tasked to do either one of the two tasks which will be specified in the query given.\nTask1 is to generate an answer to the query using the context in step by step method similar to Chain of Thought.\nTask2 is to generate a concise and comprehensive answer to the query using the contents of the context retrieved from documents or a codebase.\nPerform task1 or task2 depending on the type specified in the query \"\"\"\n\nquery_wrapper_prompt = PromptTemplate(\n    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n)\n\nquantization_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n)\n\nllm = HuggingFaceLLM(\n    model_name=selected_model,\n    tokenizer_name=selected_model,\n    query_wrapper_prompt=PromptTemplate(\"<s> [INST] {query_str} [/INST] \"),\n    context_window=8000,\n    model_kwargs={\"token\": hf_token, \"quantization_config\": quantization_config},\n    tokenizer_kwargs={\"token\": hf_token},\n    device_map='auto',\n    max_new_tokens=3000\n)\n\nSettings.llm = llm","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:54:54.003035Z","iopub.execute_input":"2024-03-26T16:54:54.003334Z","iopub.status.idle":"2024-03-26T16:56:03.482969Z","shell.execute_reply.started":"2024-03-26T16:54:54.003310Z","shell.execute_reply":"2024-03-26T16:56:03.482166Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe2ac1fbc384fe6957390d4016531de"}},"metadata":{}}]},{"cell_type":"code","source":"query = f\"explain the regex used for timefhuman\"","metadata":{"execution":{"iopub.status.busy":"2024-03-26T17:25:17.097862Z","iopub.execute_input":"2024-03-26T17:25:17.098274Z","iopub.status.idle":"2024-03-26T17:25:17.102753Z","shell.execute_reply.started":"2024-03-26T17:25:17.098242Z","shell.execute_reply":"2024-03-26T17:25:17.101794Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def retrieveNodes(query, nodes, k):\n    retriever = BM25Retriever.from_defaults(nodes = nodes, similarity_top_k=k)\n    nodes = retriever.retrieve(query) \n    return nodes if nodes else []\n\ncot_nodes = retrieveNodes(query, nodes, 4)\nbest_nodes = sorted(cot_nodes, key=lambda x: x.get_score(), reverse=True)[:2]\n\ntask1_prompt = f\"\"\"task1: \"Chain of Thought answer\" - Use the context from the documents retrieved to give a step by step answer to the query specified.\nFocus on incorporating key terms, synonyms, related concepts, and descriptive phrases to enhance the answer's scope and accuracy.\nExample:\ncontext: {best_nodes},\nquery: {query},\nanswer: Let's think step by step.... generate the answer step by step... max 5-6 steps\"\"\"\n\nquery_engine = index.as_query_engine(streaming=True)\nstreaming_response = query_engine.query(task1_prompt)\nstreaming_response.print_response_stream()\ncot_output = streaming_response.response_txt","metadata":{"execution":{"iopub.status.busy":"2024-03-26T17:25:24.078830Z","iopub.execute_input":"2024-03-26T17:25:24.079779Z","iopub.status.idle":"2024-03-26T17:27:49.841689Z","shell.execute_reply.started":"2024-03-26T17:25:24.079734Z","shell.execute_reply":"2024-03-26T17:27:49.840773Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"1. The context provided includes a list of regular expression (regex) patterns called `timefhuman_patterns`.\n2. One of the patterns in `timefhuman_patterns` is `r'(\\:\\d{2}:\\d{2}:\\d{2})'`, which matches a time format with hours, minutes, and seconds.\n3. Another pattern in `timefhuman_patterns` is `r'\\b(?:last|past|this|next|coming|upcoming)\\s*(mon|tue|wed|thu|fri|sat|sun|monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\s*(?:\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?(?:\\sfrom\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?(?:\\sto\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?\\b`. This pattern matches phrases like \"last Monday\", \"next Tuesday\", \"yesterday at 5 PM UTC\", etc.\n4. The pattern starts by matching one or more words like \"last\", \"past\", \"this\", \"next\", \"coming\", or \"upcoming\".\n5. Then it matches a day of the week or its abbreviated form, such as \"Monday\" or \"Mon\".\n6. Optionally, it matches a time in the format \"HH:MM [UTC|UTC]\", which can be followed by \"from\" and another time, or \"to\" and another time.\n7. The regex uses various flags and constructs like `(?:)`, `\\b`, and `(?:\\s)` to define groups and match specific patterns.\n8. The regex is used in the `timefhuman` function to parse human-readable time strings and convert them into datetime objects.","output_type":"stream"}]},{"cell_type":"code","source":"qa_nodes = retrieveNodes(query+cot_output, nodes, 3)\nbest_nodes = sorted(qa_nodes, key=lambda x: x.get_score(), reverse=True)[:2]\n\ntask2_prompt = f\"\"\"task2: \"Answer using context\" - You are given context: {best_nodes} retrieved using the query: {query}. You have to to use the content\nprovided in the context and output a concise and comprehensive answer to the query\"\"\"\n\nstreaming_response = query_engine.query(task2_prompt)\nstreaming_response.print_response_stream()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T17:28:48.230780Z","iopub.execute_input":"2024-03-26T17:28:48.231475Z","iopub.status.idle":"2024-03-26T17:32:18.164766Z","shell.execute_reply.started":"2024-03-26T17:28:48.231440Z","shell.execute_reply":"2024-03-26T17:32:18.163857Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"The regex patterns used for `timefhuman` in the context are defined in the script as follows:\n\n```python\ntimefhuman_patterns = [\n   r'(?:(?:last|past|this|next|coming|upcoming)\\s)?(?:mon(?:day)?|tue(?:sday)?|wed(?:nesday)?|thu(?:rsday)?|fri(?:day)?|sat(?:urday)?|sun(?:day)?)(?:\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?(?:\\sfrom\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?(?:\\sto\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)',\n   r'\\b(?:yesterday|today|tomorrow)(?:\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?(?:\\sto\\s\\d{1,2}(?::\\d{2})?(?:\\sUTC)?)?)?\\b',\n   r'\\b((last|past|coming|next|upcoming)\\s(mon|tue|wed|thu|fri|sat|sun|monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\s(noon|afternoon|midnight))\\b'\n]\n```\n\nThe first pattern `timefhuman_patterns[0]` matches various phrases related to days of the week and their relative positions in time, such as \"last Monday\", \"next Tuesday\", \"yesterday at 3 PM UTC\", \"tomorrow at 5 PM UTC\", and \"from yesterday to tomorrow\". The pattern also allows for optional hours, minutes, and UTC timezone specification.\n\nThe second pattern `timefhuman_patterns[1]` matches phrases like \"yesterday\", \"today\", and \"tomorrow\" with an optional hour and UTC timezone specification.\n\nThe third pattern `timefhuman_patterns[2]` matches phrases like \"last week Monday\", \"next Friday noon\", and \"yesterday at midnight\".\n\nThese patterns are used to extract datetime information from text using the `timefhuman` library.","output_type":"stream"}]}]}